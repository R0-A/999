{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6085986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "5555\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if device.type == 'cuda':\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "\n",
    "\n",
    "def dropout_layer(X, dropout):\n",
    "    assert 0 <= dropout <= 1\n",
    "    # 在本情况中，所有元素都被丢弃\n",
    "    if dropout == 1:\n",
    "        return torch.zeros_like(X)\n",
    "    # 在本情况中，所有元素都被保留\n",
    "    if dropout == 0:\n",
    "        return X\n",
    "    mask = (torch.rand(X.shape) > dropout).float() \n",
    "    return mask * X / (1.0 - dropout) # 除法是为了保持输出的scale不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0998cd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11., 12., 13., 14., 15.]])\n",
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11., 12., 13., 14., 15.]])\n",
      "tensor([[ 0.,  0.,  4.,  6.,  8., 10.,  0.,  0.],\n",
      "        [16.,  0.,  0., 22.,  0., 26.,  0., 30.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "X= torch.arange(16, dtype = torch.float32).reshape((2, 8))\n",
    "print(X)\n",
    "print(dropout_layer(X, 0.))\n",
    "print(dropout_layer(X, 0.5))\n",
    "print(dropout_layer(X, 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "352c7c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs, num_outputs, num_hiddens1, num_hiddens2 = 784, 10, 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b242f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout1, dropout2 = 0.2, 0.5\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, num_hiddens1, num_hiddens2,\n",
    "                 is_training = True):\n",
    "        super(Net, self).__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.training = is_training\n",
    "        self.lin1 = nn.Linear(num_inputs, num_hiddens1)\n",
    "        self.lin2 = nn.Linear(num_hiddens1, num_hiddens2)\n",
    "        self.lin3 = nn.Linear(num_hiddens2, num_outputs)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        H1 = self.relu(self.lin1(X.reshape((-1, self.num_inputs))))\n",
    "        # 只有在训练模型时才使用dropout\n",
    "        if self.training == True:\n",
    "            # 在第一个全连接层之后添加一个dropout层\n",
    "            H1 = dropout_layer(H1, dropout1)\n",
    "        H2 = self.relu(self.lin2(H1))\n",
    "        if self.training == True:\n",
    "            # 在第二个全连接层之后添加一个dropout层\n",
    "            H2 = dropout_layer(H2, dropout2)\n",
    "        out = self.lin3(H2)\n",
    "        return out\n",
    "\n",
    "\n",
    "net = Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "348161b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'd2l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 115\u001b[0m\n\u001b[1;32m    113\u001b[0m num_epochs, lr, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m256\u001b[39m\n\u001b[1;32m    114\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m train_iter, test_iter \u001b[38;5;241m=\u001b[39m \u001b[43md2l\u001b[49m\u001b[38;5;241m.\u001b[39mload_data_fashion_mnist(batch_size)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# ✅ 关键：将模型移到GPU\u001b[39;00m\n\u001b[1;32m    118\u001b[0m net \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# 假设net已经定义\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd2l' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ============ 添加设备设置 ============\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "def accuracy(y_hat, y):  \n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "def evaluate_accuracy(net, data_iter):  \n",
    "    \"\"\"计算在指定数据集上模型的精度\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()\n",
    "    metric = Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            # ✅ 修复：添加数据移动\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "class Accumulator:  \n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def train_epoch_ch3(net, train_iter, loss, updater):  \n",
    "    \"\"\"训练模型一个迭代周期\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    metric = Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        # ✅ 保持原有的数据移动\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.mean().backward()\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.sum().backward()\n",
    "            updater(X.shape[0])\n",
    "        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n",
    "\n",
    "class Animator:  \n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(10, 8)):\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        d2l.use_svg_display()\n",
    "        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        self.config_axes = lambda: d2l.set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):  \n",
    "    \"\"\"训练模型\"\"\"\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 1],\n",
    "                        legend=['train loss', 'train acc', 'test acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "        animator.add(epoch + 1, train_metrics + (test_acc,))\n",
    "    train_loss, train_acc = train_metrics\n",
    "    assert train_loss < 0.5, train_loss\n",
    "    assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "    assert test_acc <= 1 and test_acc > 0.7, test_acc\n",
    "\n",
    "# ============ 主训练代码 ============\n",
    "num_epochs, lr, batch_size = 30, 0.5, 256\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "\n",
    "# ✅ 关键：将模型移到GPU\n",
    "net = net.to(device)  # 假设net已经定义\n",
    "\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88fdda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Flatten(),\n",
    "        nn.Linear(784, 256),\n",
    "        nn.ReLU(),\n",
    "        # 在第一个全连接层之后添加一个dropout层\n",
    "        nn.Dropout(dropout1),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.ReLU(),\n",
    "        # 在第二个全连接层之后添加一个dropout层\n",
    "        nn.Dropout(dropout2),\n",
    "        nn.Linear(256, 10))\n",
    " \n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "net.apply(init_weights);\n",
    "\n",
    "\n",
    "net= net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed612cdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_ch3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 107\u001b[0m, in \u001b[0;36mtrain_ch3\u001b[0;34m(net, train_iter, test_iter, loss, num_epochs, updater)\u001b[0m\n\u001b[1;32m    104\u001b[0m animator \u001b[38;5;241m=\u001b[39m Animator(xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m, xlim\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, num_epochs], ylim\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    105\u001b[0m                     legend\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain acc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest acc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m--> 107\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch_ch3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdater\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m evaluate_accuracy(net, test_iter)\n\u001b[1;32m    109\u001b[0m     animator\u001b[38;5;241m.\u001b[39madd(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, train_metrics \u001b[38;5;241m+\u001b[39m (test_acc,))\n",
      "Cell \u001b[0;32mIn[26], line 46\u001b[0m, in \u001b[0;36mtrain_epoch_ch3\u001b[0;34m(net, train_iter, loss, updater)\u001b[0m\n\u001b[1;32m     43\u001b[0m metric \u001b[38;5;241m=\u001b[39m Accumulator(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m train_iter:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# 计算梯度并更新参数\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     l \u001b[38;5;241m=\u001b[39m loss(y_hat, y)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(updater, torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer):\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;66;03m# 使用PyTorch内置的优化器和损失函数\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"599.945312pt\" height=\"478.720781pt\" viewBox=\"0 0 599.945312 478.720781\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-09-20T22:07:27.452916</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 478.720781 \n",
       "L 599.945312 478.720781 \n",
       "L 599.945312 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 27.896875 454.519219 \n",
       "L 585.896875 454.519219 \n",
       "L 585.896875 10.999219 \n",
       "L 27.896875 10.999219 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m14a8671a5b\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m14a8671a5b\" x=\"27.896875\" y=\"454.519219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(21.048438 469.117656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"WenQuanYiMicroHei-30\" d=\"M 3225 2291 \n",
       "Q 3225 1738 3145 1300 \n",
       "Q 3066 863 2889 559 \n",
       "Q 2713 256 2434 96 \n",
       "Q 2156 -63 1759 -63 \n",
       "Q 1391 -63 1117 96 \n",
       "Q 844 256 664 559 \n",
       "Q 484 863 395 1300 \n",
       "Q 306 1738 306 2291 \n",
       "Q 306 2844 386 3281 \n",
       "Q 466 3719 639 4020 \n",
       "Q 813 4322 1089 4481 \n",
       "Q 1366 4641 1759 4641 \n",
       "Q 2131 4641 2406 4483 \n",
       "Q 2681 4325 2862 4023 \n",
       "Q 3044 3722 3134 3284 \n",
       "Q 3225 2847 3225 2291 \n",
       "z\n",
       "M 884 2291 \n",
       "Q 884 1822 931 1472 \n",
       "Q 978 1122 1081 889 \n",
       "Q 1184 656 1351 539 \n",
       "Q 1519 422 1759 422 \n",
       "Q 2000 422 2169 537 \n",
       "Q 2338 653 2445 884 \n",
       "Q 2553 1116 2601 1467 \n",
       "Q 2650 1819 2650 2291 \n",
       "Q 2650 2759 2601 3109 \n",
       "Q 2553 3459 2445 3690 \n",
       "Q 2338 3922 2169 4037 \n",
       "Q 2000 4153 1759 4153 \n",
       "Q 1519 4153 1351 4037 \n",
       "Q 1184 3922 1081 3690 \n",
       "Q 978 3459 931 3109 \n",
       "Q 884 2759 884 2291 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"WenQuanYiMicroHei-2e\" d=\"M 459 347 \n",
       "Q 459 466 490 548 \n",
       "Q 522 631 575 682 \n",
       "Q 628 734 700 757 \n",
       "Q 772 781 856 781 \n",
       "Q 938 781 1011 757 \n",
       "Q 1084 734 1137 682 \n",
       "Q 1191 631 1222 548 \n",
       "Q 1253 466 1253 347 \n",
       "Q 1253 231 1222 148 \n",
       "Q 1191 66 1137 12 \n",
       "Q 1084 -41 1011 -66 \n",
       "Q 938 -91 856 -91 \n",
       "Q 772 -91 700 -66 \n",
       "Q 628 -41 575 12 \n",
       "Q 522 66 490 148 \n",
       "Q 459 231 459 347 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-30\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-2e\" x=\"55.078125\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-30\" x=\"81.884766\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m14a8671a5b\" x=\"139.496875\" y=\"454.519219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(132.648438 469.117656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"WenQuanYiMicroHei-32\" d=\"M 3150 0 \n",
       "L 300 0 \n",
       "L 300 488 \n",
       "L 1394 1678 \n",
       "Q 1628 1931 1812 2140 \n",
       "Q 1997 2350 2126 2550 \n",
       "Q 2256 2750 2325 2951 \n",
       "Q 2394 3153 2394 3391 \n",
       "Q 2394 3575 2341 3715 \n",
       "Q 2288 3856 2189 3954 \n",
       "Q 2091 4053 1956 4103 \n",
       "Q 1822 4153 1656 4153 \n",
       "Q 1359 4153 1120 4033 \n",
       "Q 881 3913 666 3725 \n",
       "L 347 4097 \n",
       "Q 472 4209 615 4307 \n",
       "Q 759 4406 925 4478 \n",
       "Q 1091 4550 1275 4592 \n",
       "Q 1459 4634 1663 4634 \n",
       "Q 1963 4634 2205 4550 \n",
       "Q 2447 4466 2615 4308 \n",
       "Q 2784 4150 2876 3923 \n",
       "Q 2969 3697 2969 3413 \n",
       "Q 2969 3147 2886 2906 \n",
       "Q 2803 2666 2658 2433 \n",
       "Q 2513 2200 2311 1965 \n",
       "Q 2109 1731 1875 1478 \n",
       "L 997 544 \n",
       "L 997 519 \n",
       "L 3150 519 \n",
       "L 3150 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-30\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-2e\" x=\"55.078125\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-32\" x=\"81.884766\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m14a8671a5b\" x=\"251.096875\" y=\"454.519219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(244.248438 469.117656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"WenQuanYiMicroHei-34\" d=\"M 3397 1025 \n",
       "L 2731 1025 \n",
       "L 2731 0 \n",
       "L 2181 0 \n",
       "L 2181 1025 \n",
       "L 72 1025 \n",
       "L 72 1522 \n",
       "L 2144 4594 \n",
       "L 2731 4594 \n",
       "L 2731 1544 \n",
       "L 3397 1544 \n",
       "L 3397 1025 \n",
       "z\n",
       "M 2181 1544 \n",
       "L 2181 2656 \n",
       "Q 2181 2831 2186 3023 \n",
       "Q 2191 3216 2197 3398 \n",
       "Q 2203 3581 2211 3740 \n",
       "Q 2219 3900 2222 4006 \n",
       "L 2194 4006 \n",
       "Q 2172 3944 2139 3867 \n",
       "Q 2106 3791 2067 3714 \n",
       "Q 2028 3638 1987 3566 \n",
       "Q 1947 3494 1913 3444 \n",
       "L 628 1544 \n",
       "L 2181 1544 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-30\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-2e\" x=\"55.078125\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-34\" x=\"81.884766\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m14a8671a5b\" x=\"362.696875\" y=\"454.519219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(355.848438 469.117656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"WenQuanYiMicroHei-36\" d=\"M 353 1953 \n",
       "Q 353 2281 386 2606 \n",
       "Q 419 2931 501 3229 \n",
       "Q 584 3528 728 3784 \n",
       "Q 872 4041 1094 4230 \n",
       "Q 1316 4419 1625 4526 \n",
       "Q 1934 4634 2350 4634 \n",
       "Q 2409 4634 2481 4631 \n",
       "Q 2553 4628 2626 4620 \n",
       "Q 2700 4613 2767 4602 \n",
       "Q 2834 4591 2888 4575 \n",
       "L 2888 4091 \n",
       "Q 2778 4128 2640 4147 \n",
       "Q 2503 4166 2369 4166 \n",
       "Q 2088 4166 1873 4098 \n",
       "Q 1659 4031 1503 3909 \n",
       "Q 1347 3788 1242 3619 \n",
       "Q 1138 3450 1072 3245 \n",
       "Q 1006 3041 975 2809 \n",
       "Q 944 2578 934 2328 \n",
       "L 972 2328 \n",
       "Q 1034 2441 1123 2539 \n",
       "Q 1213 2638 1331 2708 \n",
       "Q 1450 2778 1598 2818 \n",
       "Q 1747 2859 1931 2859 \n",
       "Q 2228 2859 2468 2767 \n",
       "Q 2709 2675 2878 2497 \n",
       "Q 3047 2319 3139 2061 \n",
       "Q 3231 1803 3231 1472 \n",
       "Q 3231 1116 3134 831 \n",
       "Q 3038 547 2856 348 \n",
       "Q 2675 150 2419 43 \n",
       "Q 2163 -63 1844 -63 \n",
       "Q 1531 -63 1257 59 \n",
       "Q 984 181 784 431 \n",
       "Q 584 681 468 1059 \n",
       "Q 353 1438 353 1953 \n",
       "z\n",
       "M 1838 416 \n",
       "Q 2025 416 2179 480 \n",
       "Q 2334 544 2446 673 \n",
       "Q 2559 803 2620 1001 \n",
       "Q 2681 1200 2681 1472 \n",
       "Q 2681 1691 2629 1864 \n",
       "Q 2578 2038 2475 2159 \n",
       "Q 2372 2281 2217 2347 \n",
       "Q 2063 2413 1856 2413 \n",
       "Q 1647 2413 1473 2339 \n",
       "Q 1300 2266 1178 2148 \n",
       "Q 1056 2031 989 1881 \n",
       "Q 922 1731 922 1581 \n",
       "Q 922 1372 980 1164 \n",
       "Q 1038 956 1152 790 \n",
       "Q 1266 625 1437 520 \n",
       "Q 1609 416 1838 416 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-30\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-2e\" x=\"55.078125\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-36\" x=\"81.884766\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m14a8671a5b\" x=\"474.296875\" y=\"454.519219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(467.448438 469.117656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"WenQuanYiMicroHei-38\" d=\"M 1766 4641 \n",
       "Q 2028 4641 2261 4572 \n",
       "Q 2494 4503 2670 4365 \n",
       "Q 2847 4228 2950 4022 \n",
       "Q 3053 3816 3053 3541 \n",
       "Q 3053 3331 2990 3162 \n",
       "Q 2928 2994 2818 2858 \n",
       "Q 2709 2722 2559 2614 \n",
       "Q 2409 2506 2234 2419 \n",
       "Q 2416 2322 2589 2203 \n",
       "Q 2763 2084 2898 1936 \n",
       "Q 3034 1788 3117 1603 \n",
       "Q 3200 1419 3200 1191 \n",
       "Q 3200 903 3095 670 \n",
       "Q 2991 438 2802 275 \n",
       "Q 2613 113 2348 25 \n",
       "Q 2084 -63 1766 -63 \n",
       "Q 1422 -63 1155 21 \n",
       "Q 888 106 705 264 \n",
       "Q 522 422 426 650 \n",
       "Q 331 878 331 1166 \n",
       "Q 331 1400 401 1587 \n",
       "Q 472 1775 590 1925 \n",
       "Q 709 2075 871 2190 \n",
       "Q 1034 2306 1216 2394 \n",
       "Q 1063 2491 928 2605 \n",
       "Q 794 2719 695 2859 \n",
       "Q 597 3000 539 3170 \n",
       "Q 481 3341 481 3547 \n",
       "Q 481 3819 586 4023 \n",
       "Q 691 4228 869 4365 \n",
       "Q 1047 4503 1280 4572 \n",
       "Q 1513 4641 1766 4641 \n",
       "z\n",
       "M 891 1159 \n",
       "Q 891 994 941 855 \n",
       "Q 991 716 1097 617 \n",
       "Q 1203 519 1365 464 \n",
       "Q 1528 409 1753 409 \n",
       "Q 1972 409 2139 464 \n",
       "Q 2306 519 2418 620 \n",
       "Q 2531 722 2587 865 \n",
       "Q 2644 1009 2644 1184 \n",
       "Q 2644 1347 2583 1478 \n",
       "Q 2522 1609 2408 1721 \n",
       "Q 2294 1834 2134 1934 \n",
       "Q 1975 2034 1778 2131 \n",
       "L 1684 2175 \n",
       "Q 1291 1988 1091 1745 \n",
       "Q 891 1503 891 1159 \n",
       "z\n",
       "M 1759 4166 \n",
       "Q 1428 4166 1233 4000 \n",
       "Q 1038 3834 1038 3519 \n",
       "Q 1038 3341 1092 3212 \n",
       "Q 1147 3084 1244 2984 \n",
       "Q 1341 2884 1477 2804 \n",
       "Q 1613 2725 1772 2650 \n",
       "Q 1922 2719 2055 2800 \n",
       "Q 2188 2881 2286 2984 \n",
       "Q 2384 3088 2440 3219 \n",
       "Q 2497 3350 2497 3519 \n",
       "Q 2497 3834 2300 4000 \n",
       "Q 2103 4166 1759 4166 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-30\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-2e\" x=\"55.078125\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-38\" x=\"81.884766\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m14a8671a5b\" x=\"585.896875\" y=\"454.519219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(579.048437 469.117656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"WenQuanYiMicroHei-31\" d=\"M 2222 0 \n",
       "L 1672 0 \n",
       "L 1672 2853 \n",
       "Q 1672 2988 1673 3141 \n",
       "Q 1675 3294 1679 3445 \n",
       "Q 1684 3597 1689 3736 \n",
       "Q 1694 3875 1697 3981 \n",
       "Q 1644 3925 1603 3884 \n",
       "Q 1563 3844 1520 3806 \n",
       "Q 1478 3769 1431 3726 \n",
       "Q 1384 3684 1319 3628 \n",
       "L 856 3250 \n",
       "L 556 3634 \n",
       "L 1753 4569 \n",
       "L 2222 4569 \n",
       "L 2222 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-31\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-2e\" x=\"55.078125\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-30\" x=\"81.884766\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path id=\"m2f65cafe54\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2f65cafe54\" x=\"27.896875\" y=\"454.519219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(7.2 458.318437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-30\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-2e\" x=\"55.078125\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-30\" x=\"81.884766\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2f65cafe54\" x=\"27.896875\" y=\"365.815219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(7.2 369.614437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-30\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-2e\" x=\"55.078125\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-32\" x=\"81.884766\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2f65cafe54\" x=\"27.896875\" y=\"277.111219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(7.2 280.910437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-30\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-2e\" x=\"55.078125\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-34\" x=\"81.884766\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2f65cafe54\" x=\"27.896875\" y=\"188.407219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(7.2 192.206437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-30\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-2e\" x=\"55.078125\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-36\" x=\"81.884766\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2f65cafe54\" x=\"27.896875\" y=\"99.703219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(7.2 103.502437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-30\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-2e\" x=\"55.078125\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-38\" x=\"81.884766\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2f65cafe54\" x=\"27.896875\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(7.2 14.798437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-31\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-2e\" x=\"55.078125\"/>\n",
       "       <use xlink:href=\"#WenQuanYiMicroHei-30\" x=\"81.884766\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 27.896875 454.519219 \n",
       "L 27.896875 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 585.896875 454.519219 \n",
       "L 585.896875 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 27.896875 454.519219 \n",
       "L 585.896875 454.519219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 27.896875 10.999219 \n",
       "L 585.896875 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbcbd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
